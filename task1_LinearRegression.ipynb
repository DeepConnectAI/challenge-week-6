{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task1_LinearRegression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tWQnVjqfFwv",
        "colab_type": "text"
      },
      "source": [
        "## Cross validation, L1(Lasso) and L2 (Ridge) regularization using Linear Regression\n",
        "\n",
        "We will use cross validation, lasso and ridge regression in this lab.\n",
        "\n",
        "Specifically speaking, <br>\n",
        "Regularization basically adds the penalty as model complexity increases.<br>\n",
        "Cross validation is used to evaluate how well our model can generalize on the dataset. <br>\n",
        "\n",
        "We will be using r2 score in this lab. It provides an indication of goodness of fit and therefore a measure of how well unseen samples are likely to be predicted by the model.\n",
        "\n",
        "\n",
        "In this task, we will explore the following things on linear regression model:\n",
        "- Cross Validation\n",
        "- L1 regularization (Lasso regression)\n",
        "- L2 regularization (Ridge regression)\n",
        "\n",
        "\n",
        "#### Dataset\n",
        "The dataset is available at \"data/bike.csv\" in the respective challenge's repo.<br>\n",
        "\n",
        "The dataset is __modified version__ of the dataset 'bike.csv' provided by UCI Machine Learning repository.\n",
        "\n",
        "Original dataset: https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset\n",
        "\n",
        "#### Objective\n",
        "To learn about how cross validation, L1 regularization and L2 regularization work.\n",
        "\n",
        "#### Tasks\n",
        "- load the dataset.\n",
        "- perform pre-processing on the data.\n",
        "- remove registered and casual features to prevent data leakage.\n",
        "- construct train and test dataset.\n",
        "- create a linear regression model.\n",
        "- check the r2 score of the initial linear regression model on train and test dataset\n",
        "- observe distribution of weights in the initial linear regression model. \n",
        "- split the dataset into k consecutive folds.\n",
        "- calculate cross validation score for the k fold and check how well our model can generalize on the training dataset.\n",
        "- checking the variance threshold of dataset and remove features with low variance.\n",
        "- apply L1 regularization on the dataset and check the r2_score.\n",
        "- visualize the distribution of weights on the lasso regression model.\n",
        "- apply L2 regularization on the dataset and check the r2_score.\n",
        "- visualize the distribution of weights on the ridge regression model. \n",
        "\n",
        "#### Further fun\n",
        "- apply RFE on the dataset to automatically remove uneccessary features which would prevent overfitting.\n",
        "- don't remove casual and registered features and check the effect of data leakage on the model\n",
        "- implement lasso and ridge regression without using inbuilt librarires.\n",
        "- apply elastic net to visualize the effect of both ridge and lasso regression.\n",
        "\n",
        "\n",
        "#### Helpful links\n",
        "- Cross validation : https://machinelearningmastery.com/k-fold-cross-validation/#:~:text=Cross%2Dvalidation%20is%20a%20resampling,k%2Dfold%20cross%2Dvalidation.\n",
        "- Cross validation: https://scikit-learn.org/stable/modules/cross_validation.html\n",
        "- L1 and L2 regularization : https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b\n",
        "- L1 and L2 regularization : https://www.youtube.com/watch?v=9lRv01HDU0s&list=PLZoTAELRMXVPBTrWtJkn3wWQxZkmTXGwe&index=30&t=904s\n",
        "- r2_score: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score\n",
        "- pd.get_dummies() and One Hot Encoding: https://queirozf.com/entries/one-hot-encoding-a-feature-on-a-pandas-dataframe-an-example\n",
        "- Data Leakage : \"https://machinelearningmastery.com/data-leakage-machine-learning/\n",
        "- sklearn k-fold : https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
        "- sklearn cross_val_score : https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html?highlight=cross_val_score#sklearn.model_selection.cross_val_score\n",
        "- sklearn lasso regression : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html?highlight=lasso#sklearn.linear_model.Lasso\n",
        "- sklearn ridge regression : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html?highlight=ridge#sklearn.linear_model.Ridge\n",
        "- RFE : https://machinelearningmastery.com/rfe-feature-selection-in-python/\n",
        "- RFE sklearn : https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html\n",
        "- Use slack for doubts: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mRl7KPgwjRHI",
        "colab": {}
      },
      "source": [
        "#import the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sklearn processing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Sklearn linear regression model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Sklearn regression model evaluation functions\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Perform feature selection using a variance threshold\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "# Feature selection using Recursive Feature Elimimation\n",
        "from sklearn.feature_selection import RFE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vq1jiQz-kIpA",
        "colab": {}
      },
      "source": [
        "#load the data and inspect the first 5 rows\n",
        "data = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pw5T1NvekL65",
        "colab": {}
      },
      "source": [
        "# print the data types of each feature name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RE0sjCi4kREL",
        "colab": {}
      },
      "source": [
        "# check for null values in each column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jWJz8TAgketK",
        "colab": {}
      },
      "source": [
        "# print out the unique values of the features ['season', 'year', 'weather', 'promotion_type']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1nkDe68NkyZ2",
        "colab": {}
      },
      "source": [
        "# print out the value counts (frequency of occurence) of the unique values in these features ['season', 'year', 'weather', 'promotion_type']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yIsIIQWFmJRK",
        "colab": {}
      },
      "source": [
        "# print the shape of data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xXsOHMilNTz",
        "colab": {}
      },
      "source": [
        "# drop the feature 'id' as it has no information to present.\n",
        "\n",
        "data = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i4BXZ-_qmNYh",
        "colab": {}
      },
      "source": [
        "# print the shape of data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1G-eQ8ULmO3J",
        "colab": {}
      },
      "source": [
        "# one hot encode the categorical columns.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qcf6heimmZaQ",
        "colab": {}
      },
      "source": [
        "# print the shape of data \n",
        "# notice the increase in the no. of features\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vLOkfanFfWDK"
      },
      "source": [
        "Notice that cnt = registered + casual<br>\n",
        "To avoid data leakage remove the feature 'registered' and 'casual' feature. <br>\n",
        "To understand more about data leakge refer the data leakage article mentioned in the uselful links."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vZ2HK7RGmO63",
        "colab": {}
      },
      "source": [
        "# Split the dataset into X and y\n",
        "# notice the target variable is 'cnt'\n",
        "X = ?\n",
        "y = ?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6blYZrz7mPBG",
        "colab": {}
      },
      "source": [
        "# Apply scaling if our data is spread across wide differences of range values.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ad4MfGe1mPDk",
        "colab": {}
      },
      "source": [
        "# split the dataset into X_train, X_test, y_train, y_test\n",
        "# play around with test sizes.\n",
        "\n",
        "test_size = ?\n",
        "X_train, X_test, y_train, y_test = ?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6czlxW2tnQqP",
        "colab": {}
      },
      "source": [
        "# print the shapes\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w-lp9O74nUm7",
        "colab": {}
      },
      "source": [
        "# build the Linear Regression model.\n",
        "\n",
        "model = ?\n",
        "\n",
        "# fit the model on the training data\n",
        "model.fit(?, ?)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NmXHyTOTnvM7",
        "colab": {}
      },
      "source": [
        "# custom score function independment of the model.\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "def custom_score(model, X, y):\n",
        "  \"\"\"Get the model prediction scores using the provided input and target features\"\"\"\n",
        "   predictions = model.predict(?)\n",
        "   return r2_score(?, ?)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ga_f-66JoVri",
        "colab": {}
      },
      "source": [
        "# print the score on training set\n",
        "\n",
        "print(\"On Training set : \", custom_score(model, ?, ?))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IKmlrtpDoilu",
        "colab": {}
      },
      "source": [
        "# print the score on the test set\n",
        "\n",
        "print(\"On testing set : \", custom_score(model, ?, ?))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cYyTP91_pB-u"
      },
      "source": [
        "Do not edit the below code. Observe the distribution of weights. \n",
        "Which feature has the maximum coefficient ? <br>\n",
        "Keep this figure as a base reference for visualizing the effects of l1-norm and l2-norm later in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ck8Vx1bWozcf",
        "colab": {}
      },
      "source": [
        "# custom summary function to plot the coefficients / weightage of the features.\n",
        "def custom_summary(model, column_names, title):\n",
        "    '''Show a summary of the trained linear regression model'''\n",
        "\n",
        "    # Plot the coeffients as bars\n",
        "    fig = plt.figure(figsize=(8,len(column_names)/3))\n",
        "    fig.suptitle(title, fontsize=16)\n",
        "    rects = plt.barh(column_names, model.coef_,color=\"lightblue\")\n",
        "\n",
        "    # Annotate the bars with the coefficient values\n",
        "    for rect in rects:\n",
        "        width = round(rect.get_width(),4)\n",
        "        plt.gca().annotate('  {}  '.format(width),\n",
        "                    xy=(0, rect.get_y()),\n",
        "                    xytext=(0,2),  \n",
        "                    textcoords=\"offset points\",  \n",
        "                    ha='left' if width<0 else 'right', va='bottom')        \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QuyEBDrYotzb",
        "colab": {}
      },
      "source": [
        "# coefficients plot\n",
        "# let's call the above custom function.\n",
        "\n",
        "custom_summary(model, X_train.columns, \"Linear Regression coefficients.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E77vWyd7plQ2",
        "colab": {}
      },
      "source": [
        "# evaluate the model with k = 10 Fold Cross validation\n",
        "\n",
        "model = KFold(n_splits = ?, shuffle = True, random_state = 100)\n",
        "results = cross_val_score(?, ?, ?, scoring = 'r2', cv = folds)\n",
        "\n",
        "print(type(model).__name__)\n",
        "print(\"kFoldCV:\")\n",
        "print(\"Fold R2 scores:\", results)\n",
        "print(\"Mean R2 score:\", results.mean())\n",
        "print(\"Std R2 score:\", results.std())\n",
        "print(\"Generalizability on training set : \", results.mean(), \" +/- \", results.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uzAg3gtfcv9z",
        "colab": {}
      },
      "source": [
        "# print the score on testing set.\n",
        "print('On test set : ', score(model, ?, ?))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xNVstf3MRWTS"
      },
      "source": [
        "Feature Selection using Variance Thresholding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3fWmra-LRSvk",
        "colab": {}
      },
      "source": [
        "print(\"Original shape of X_train : \", X_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZdfMwVybRl9o",
        "colab": {}
      },
      "source": [
        "# check the variance of X\n",
        "\n",
        "X.var()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kk36hVk_Rv6l"
      },
      "source": [
        "Remove low variance features using Variance Threshold. \n",
        "\n",
        "Note : If the variance is less, it implies the values of that particular feature spans limited range of values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3RkbbmcuRtkJ",
        "colab": {}
      },
      "source": [
        "# play around with the threshold values\n",
        "\n",
        "sel = VarianceThreshold(threshold = (0.01))\n",
        "sel.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bk525DOySWJp",
        "colab": {}
      },
      "source": [
        "# do not edit.\n",
        "\n",
        "selected_features = list(X_train.columns[sel.get_support()])\n",
        "print(\"Selected features : \", selected_features)\n",
        "print(\"Removed features : \", list(X_train.columns[~sel.get_support()]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k1AQhlAhSXI5",
        "colab": {}
      },
      "source": [
        "#transform / remove the low variance features\n",
        "\n",
        "X_train = sel.transform(X_train)\n",
        "X_test = sel.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UH8mZBs3S-i3"
      },
      "source": [
        "## Lasso Regression : L1 - norm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0XTVvk4gS98-",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(?, ?, test_size = ?, random_state = 100)\n",
        "\n",
        "# hyperparamater alpha : controls the degree of penaliation.\n",
        "# play around with alpha values.\n",
        "alpha = 1.0\n",
        "\n",
        "#create the model\n",
        "model = Lasso(alpha = alpha)\n",
        "\n",
        "#fit the model on training data\n",
        "model.fit(?, ?)\n",
        "\n",
        "#calculate the score on training data\n",
        "predictions = model.predict(?)\n",
        "print(\"On train set : \", custom_score(y_train, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PD4NpuxYTWoV",
        "colab": {}
      },
      "source": [
        "#evaluate the model on testing data\n",
        "predictions = model.predict(?)\n",
        "print(\"On test set : \", custom_score(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bN7w1V5hT2Dp",
        "colab": {}
      },
      "source": [
        "# visualize the coefficients.\n",
        "# compare the results with the plot obtained earlier.\n",
        "\n",
        "custom_summary(model, X_train.columns, \"Lasso Regression Coefficients.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dsjziyZzUS8P"
      },
      "source": [
        "We can see that Lasso regression has automatically done a lot of feature selection. Some columns might have zero coefficients. It has been effectively removed. <br> \n",
        "The model is much more interpretable than the baseline linear regression model.\n",
        "<br>\n",
        "Hence, Lasso regression has embedded Feature Selection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O9IlW2V2UfD0"
      },
      "source": [
        "# Ridge Regression : L2 - norm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j6PRlLONUckx",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# hyperparamater alpha : controls the degree of penaliation.\n",
        "# play around with alpha values.\n",
        "alpha = 1.0\n",
        "\n",
        "#create the model\n",
        "model = Ridge(alpha = ?)\n",
        "\n",
        "#fit the model on training data\n",
        "model.fit(?, ?)\n",
        "\n",
        "#calculate the score on training data\n",
        "predictions = model.predict(?)\n",
        "print(\"On train set : \", custom_score(y_train, predictions))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jzukav_PVTG2",
        "colab": {}
      },
      "source": [
        "#evaluate the model on testing data\n",
        "predictions = model.predict(?)\n",
        "print(\"On test set : \", custom_score(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c39ZBnmvVYSA",
        "colab": {}
      },
      "source": [
        "# visualize the coefficients.\n",
        "# compare the results with the plot obtained earlier.\n",
        "\n",
        "custom_summary(model, X_train.columns, \"Ridge Regression Coefficients.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TqLF3812VefE"
      },
      "source": [
        "Ridge regression doesn't drive smaller coefficients to 0 hence it doesn't possess internal feature selection."
      ]
    }
  ]
}